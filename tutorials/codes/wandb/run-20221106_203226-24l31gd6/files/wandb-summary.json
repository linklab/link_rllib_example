{"train": 10, "episodes": 389, "timesteps": 40000, "optimizations": 1280, "train/episode_reward_mean": 294.59, "train/episode_reward_min": 11.0, "train/episode_reward_max": 500.0, "train/episode_length_mean": 294.59, "evaluation/episode_reward_mean": 500.0, "evaluation/episode_reward_min": 500.0, "evaluation/episode_reward_max": 500.0, "evaluation/episode_length_mean": 500.0, "loss": 9.528634648681969, "_timestamp": 1667734397.337276, "_runtime": 50.751312017440796, "_step": 9, "_wandb": {"runtime": 51}}