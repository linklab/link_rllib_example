{"train": 7, "episodes": 351, "timesteps": 28000, "optimizations": 896, "train/episode_reward_mean": 199.51, "train/episode_reward_min": 16.0, "train/episode_reward_max": 500.0, "train/episode_length_mean": 199.51, "evaluation/episode_reward_mean": 500.0, "evaluation/episode_reward_min": 500.0, "evaluation/episode_reward_max": 500.0, "evaluation/episode_length_mean": 500.0, "loss": 9.675064733976958, "_timestamp": 1667734258.474459, "_runtime": 35.14692282676697, "_step": 6, "_wandb": {"runtime": 36}}