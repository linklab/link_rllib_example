{"train": 8, "episodes": 372, "timesteps": 32000, "optimizations": 1024, "train/episode_reward_mean": 229.42, "train/episode_reward_min": 15.0, "train/episode_reward_max": 500.0, "train/episode_length_mean": 229.42, "evaluation/episode_reward_mean": 459.6666666666667, "evaluation/episode_reward_min": 408.0, "evaluation/episode_reward_max": 500.0, "evaluation/episode_length_mean": 459.6666666666667, "loss": 9.55919398030927, "_timestamp": 1667734578.602022, "_runtime": 32.29027795791626, "_step": 7, "_wandb": {"runtime": 33}}