{"train": 9, "episodes": 381, "timesteps": 36000, "optimizations": 1152, "train/episode_reward_mean": 256.71, "train/episode_reward_min": 16.0, "train/episode_reward_max": 500.0, "train/episode_length_mean": 256.71, "evaluation/episode_reward_mean": 452.0, "evaluation/episode_reward_min": 356.0, "evaluation/episode_reward_max": 500.0, "evaluation/episode_length_mean": 452.0, "loss": 9.411600527199365, "_timestamp": 1667733956.926969, "_runtime": 44.65332102775574, "_step": 8, "_wandb": {"runtime": 46}}