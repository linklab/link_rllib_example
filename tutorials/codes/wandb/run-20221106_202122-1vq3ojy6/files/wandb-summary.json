{"train": 9, "episodes": 401, "timesteps": 36000, "optimizations": 1152, "train/episode_reward_mean": 249.01, "train/episode_reward_min": 11.0, "train/episode_reward_max": 500.0, "train/episode_length_mean": 249.01, "evaluation/episode_reward_mean": 451.6666666666667, "evaluation/episode_reward_min": 415.0, "evaluation/episode_reward_max": 500.0, "evaluation/episode_length_mean": 451.6666666666667, "loss": 9.413263634712465, "_timestamp": 1667733725.4090948, "_runtime": 43.14029788970947, "_step": 8, "_wandb": {"runtime": 42}}