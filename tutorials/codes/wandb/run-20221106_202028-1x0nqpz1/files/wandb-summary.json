{"train": 6, "episodes": 379, "timesteps": 24000, "optimizations": 768, "train/episode_reward_mean": 160.65, "train/episode_reward_min": 12.0, "train/episode_reward_max": 500.0, "train/episode_length_mean": 160.65, "evaluation/episode_reward_mean": 370.3333333333333, "evaluation/episode_reward_min": 340.0, "evaluation/episode_reward_max": 411.0, "evaluation/episode_length_mean": 370.3333333333333, "loss": 9.496542648602558, "_timestamp": 1667733660.370569, "_runtime": 31.674992084503174, "_step": 5}