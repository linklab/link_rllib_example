{"train": 4, "episodes": 324, "timesteps": 16000, "optimizations": 512, "train/episode_reward_mean": 96.4, "train/episode_reward_min": 10.0, "train/episode_reward_max": 342.0, "train/episode_length_mean": 96.4, "evaluation/episode_reward_mean": 450.6666666666667, "evaluation/episode_reward_min": 376.0, "evaluation/episode_reward_max": 500.0, "evaluation/episode_length_mean": 450.6666666666667, "loss": 9.475160651053152, "_timestamp": 1667734179.4115882, "_runtime": 21.772767305374146, "_step": 3, "_wandb": {"runtime": 20}}