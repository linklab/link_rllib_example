{"train": 12, "episodes": 85, "timesteps": 48000, "optimizations": 312000, "train/episode_reward_mean": -111.58278102820886, "train/episode_reward_min": -205.62349051300316, "train/episode_reward_max": -92.17237924850878, "train/episode_length_mean": 561.6588235294117, "evaluation/episode_reward_mean": -104.0090262768676, "evaluation/episode_reward_min": -111.43104618791118, "evaluation/episode_reward_max": -94.94348937606759, "evaluation/episode_length_mean": 371.0, "loss": 1.820461921376409, "_timestamp": 1669084145.966443, "_runtime": 222.87050008773804, "_step": 11}